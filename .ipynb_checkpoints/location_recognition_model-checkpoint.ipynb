{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b910a2b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio onnx onnxruntime pillow fastapi uvicorn python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235f3e5c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.utils as TUtils\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import pathlib\n",
    "import onnxruntime as ort\n",
    "import io\n",
    "from fastapi import FastAPI, UploadFile, File\n",
    "from fastapi.responses import JSONResponse\n",
    "import nest_asyncio\n",
    "import uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaba50d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((32, 32)),  # Resize images to fit the network\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "batch_size = 16\n",
    "ataset = datasets.ImageFolder(root='data', transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "trainset = datasets.MNIST(root='./data/test', train=True,\n",
    "                           download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "testset = datasets.MNIST(root='./data', train=False,\n",
    "                          download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                       shuffle=False, num_workers=0)\n",
    "\n",
    "# Redefine classes as locations instead of objects\n",
    "location_classes = (\n",
    "    'New York', 'Paris', 'Tokyo', 'London',\n",
    "    'Sydney', 'Dubai', 'Rio', 'Cape Town', 'Venice', 'Hong Kong'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb5487",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(locationNet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a8bbd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Training function\n",
    "def train_model(model, trainloader, criterion, optimizer, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        batch_losses = []\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate batch loss and accuracy\n",
    "            running_loss += loss.item()\n",
    "            batch_losses.append(loss.item())\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "                \n",
    "            # Calculate epoch metrics\n",
    "        model_loss = sum(batch_losses) / len(batch_losses)\n",
    "        model_accuracy = 100 * correct / total\n",
    "        \n",
    "        test_losses.append(model_loss)\n",
    "        test_accuracies.append(model_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch+1} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "    \n",
    "    print('Finished Training')\n",
    "\n",
    "        # Plot training metrics\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs+1), epoch_losses, 'b-', label='Training Loss')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs+1), epoch_accuracies, 'r-', label='Training Accuracy')\n",
    "    plt.title('Training Accuracy per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('location_training_metrics.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return epoch_losses, epoch_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64618c40",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e7eb7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, testloader, classes):\n",
    "    # Prepare to count predictions for each class\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "    \n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "        # No gradient calculation needed\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            \n",
    "            # Store all labels and predictions for confusion matrix\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            \n",
    "            # Collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "    \n",
    "    # Print accuracy for each location\n",
    "    accuracies = []\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        accuracies.append(accuracy)\n",
    "        print(f'Accuracy for location {classname}: {accuracy:.1f}%')\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    total_correct = sum(correct_pred.values())\n",
    "    total = sum(total_pred.values())\n",
    "    overall_accuracy = 100 * total_correct / total\n",
    "    print(f'Overall location detection accuracy: {overall_accuracy:.1f}%')\n",
    "    \n",
    "        # Plot class accuracies\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(classes, accuracies, color='skyblue')\n",
    "    plt.title('Location Detection Accuracy by City')\n",
    "    plt.xlabel('Location')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add accuracy values on top of bars\n",
    "    for bar, accuracy in zip(bars, accuracies):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                f'{accuracy:.1f}%', ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45bcc44",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "print(\"Testing location detection accuracy...\")\n",
    "test_model(locationNet, testloader, location_classes)\n",
    "\n",
    "# Get some test images\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Print images with location labels\n",
    "print('Actual locations: ', ' '.join(f'{location_classes[labels[j]]}' for j in range(4)))\n",
    "imshow(TUtils.make_grid(images))\n",
    "\n",
    "# Print predicted locations\n",
    "outputs = locationNet(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted locations: ', ' '.join(f'{location_classes[predicted[j]]}' for j in range(4)))\n",
    "\n",
    "# Calculate confusion matrix for location detection\n",
    "print(\"\\nDetailed Location Detection Performance:\")\n",
    "confusion_matrix = torch.zeros(10, 10, dtype=torch.int)\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = locationNet(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            confusion_matrix[label][prediction] += 1\n",
    "\n",
    "print(\"Top misclassifications:\")\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and confusion_matrix[i][j] > 10:\n",
    "            print(f\"{location_classes[i]} mistaken as {location_classes[j]}: {confusion_matrix[i][j]} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb07a26c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = MonResNet(num_classes=5)\n",
    "model.load_state_dict(torch.load(\"model/location_recognition.pth\"))\n",
    "\n",
    "# Exemple d'entrée factice avec les bonnes dimensions [batch_size, channels, height, width]\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export du modèle vers ONNX\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"location_recognition.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    opset_version=11\n",
    ")\n",
    "\n",
    "print(\"✅ Modèle exporté avec succès en location_recognition.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e4aaa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "session = ort.InferenceSession(\"location_recognition.onnx\")\n",
    "input_name = session.get_inputs()[0].name\n",
    "\n",
    "def preprocess(image: Image.Image) -> np.ndarray:\n",
    "    image = image.resize((224, 224))\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    if image.ndim == 2:\n",
    "        image = np.stack([image] * 3, axis=-1)\n",
    "    image = image.transpose(2, 0, 1)  # [C, H, W]\n",
    "\n",
    "    # Normalisation comme pour ResNet\n",
    "    mean = np.array([0.485, 0.456, 0.406]).reshape(3, 1, 1)\n",
    "    std = np.array([0.229, 0.224, 0.225]).reshape(3, 1, 1)\n",
    "    image = (image - mean) / std\n",
    "\n",
    "    image = np.expand_dims(image, axis=0)  # [1, C, H, W]\n",
    "    return image\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    content = await file.read()\n",
    "    image = Image.open(io.BytesIO(content)).convert(\"RGB\")\n",
    "    input_tensor = preprocess(image)\n",
    "    \n",
    "    outputs = session.run(None, {input_name: input_tensor})\n",
    "    prediction = np.argmax(outputs[0])  # À adapter selon la sortie du modèle\n",
    "\n",
    "    class_names = [\"campagne\", \"foret\", \"montagne\", \"plage\", \"ville\"]\n",
    "    predicted_label = class_names[prediction] if prediction < len(class_names) else \"Inconnu\"\n",
    "\n",
    "    return JSONResponse(content={\"prediction\": predicted_label})\n",
    "\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "#Test du modèle côté back\n",
    "image = Image.open(\"miami.PNG\").convert(\"RGB\")\n",
    "input_tensor = preprocess(image)\n",
    "output = session.run(None, {input_name: input_tensor})\n",
    "print(\"Prédiction :\", class_names[np.argmax(output[0])])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
